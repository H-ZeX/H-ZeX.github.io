<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222"/>


























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2"/>

<link rel="stylesheet" href="/css/main.css?v=7.0.0"/>


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.0.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.0.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    showProcessingMessages: false,
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
        inlineMath:  [ ["$", "$"] ],
        displayMath: [ ["$$","$$"] ],
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code','a'],
        ignoreClass:"comment-content"
    },
    "HTML-CSS": {
        availableFonts: ["STIX","TeX"],
        showMathMenu: false
    }
});
MathJax.Hub.Queue(["Typeset",MathJax.Hub]);
</script>
<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  




  <meta name="description" content="Linux调度 linux内核设计与实现第4章 不同进程有不同的调度算法（这种模块化结构称为调度器类）。每个调度器都有一个优先级，不同调度器之间如何协调？拥有一个可执行进程的最高优先级的调度器会胜出，去选择接下来要执行那个进程（The highest priority scheduler class that has a runnable process wins, selecting who r">
<meta name="keywords" content="Linux,CFS,epoll">
<meta property="og:type" content="article">
<meta property="og:title" content="My Linux Note">
<meta property="og:url" content="https://h-zex.github.io/2019/05/01/My-Linux-Note/index.html">
<meta property="og:site_name" content="H-ZeX">
<meta property="og:description" content="Linux调度 linux内核设计与实现第4章 不同进程有不同的调度算法（这种模块化结构称为调度器类）。每个调度器都有一个优先级，不同调度器之间如何协调？拥有一个可执行进程的最高优先级的调度器会胜出，去选择接下来要执行那个进程（The highest priority scheduler class that has a runnable process wins, selecting who r">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2019-10-03T12:13:55.613Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="My Linux Note">
<meta name="twitter:description" content="Linux调度 linux内核设计与实现第4章 不同进程有不同的调度算法（这种模块化结构称为调度器类）。每个调度器都有一个优先级，不同调度器之间如何协调？拥有一个可执行进程的最高优先级的调度器会胜出，去选择接下来要执行那个进程（The highest priority scheduler class that has a runnable process wins, selecting who r">



  <link rel="alternate" href="/atom.xml" title="H-ZeX" type="application/atom+xml"/>




  <link rel="canonical" href="https://h-zex.github.io/2019/05/01/My-Linux-Note/"/>



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>My Linux Note | H-ZeX</title>
  




  <script async src="//www.googletagmanager.com/gtag/js?id=UA-137821328-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-137821328-1');
  </script>









  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">H-ZeX</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">H-ZeX's Coding Life</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br/>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br/>Tags</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br/>Categories</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br/>Archives</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-友情链接">

    
    
    
      
    

    

    <a href="/link" rel="section"><i class="menu-item-icon fa fa-fw fa-link"></i> <br/>友情链接</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://h-zex.github.io/2019/05/01/My-Linux-Note/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="H-ZeX"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="H-ZeX"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">My Linux Note

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-05-01 10:22:59" itemprop="dateCreated datePublished" datetime="2019-05-01T10:22:59+08:00">2019-05-01</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-10-03 20:13:55" itemprop="dateModified" datetime="2019-10-03T20:13:55+08:00">2019-10-03</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Linux/" itemprop="url" rel="index"><span itemprop="name">Linux</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <a href="/2019/05/01/My-Linux-Note/#comments" itemprop="discussionUrl">
                  <span class="post-meta-item-text">Comments: </span> <span class="post-comments-count valine-comment-count" data-xid="/2019/05/01/My-Linux-Note/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="Linux调度"><a href="#Linux调度" class="headerlink" title="Linux调度"></a>Linux调度</h3><ul>
<li>linux内核设计与实现第4章</li>
<li>不同进程有不同的调度算法（这种模块化结构称为调度器类）。每个调度器都有一个优先级，不同调度器之间如何协调？拥有一个可执行进程的最高优先级的调度器会胜出，去选择接下来要执行那个进程（The highest priority scheduler class that has a runnable process wins, selecting who runs next.）</li>
</ul>
<h4 id="CFS"><a href="#CFS" class="headerlink" title="CFS"></a>CFS</h4><ul>
<li>从Linux2.6.23开始引入</li>
<li>针对普通进程的调度器类（Linux中称为<code>SCHED_NORMAL</code>，POSIX称为<code>SCHED_OTHER</code>）</li>
<li>基于一个简单的理念：每个进程都能获得<code>1/n</code>的处理器时间（n是可运行的进程数量），任何可测量的周期内都是<code>1/n</code>（一个先运行5ms，另一个运行5ms是不满足这个理念的，要做到好像他们在10ms内同时运行，各自使用了一半的处理器能力）<blockquote>
<ul>
<li>Ref: <a href="https://www.cs.columbia.edu/~junfeng/13fa-w4118/lectures/l13-adv-sched.pdf" target="_blank" rel="noopener">https://www.cs.columbia.edu/~junfeng/13fa-w4118/lectures/l13-adv-sched.pdf</a></li>
<li>Approximate fair scheduling. Run each process once per schedule latency period(就是sched_latency_ns，用<code>sysctl -a</code>可以看到). Time slice for process Pi: <code>T * Wi/(Sum of all Wi)</code></li>
<li>Too many processes? Lower bound on smallest time slice. Schedule latency = lower bound * number of procs</li>
<li>Pick proc with weighted minimum runtime so far  <code>Virtual runtime: task-&gt;vruntime += executed time / Wi</code></li>
<li>Red-black tree, Balanced binary search tree, Ordered by vruntime as key, O(lgN) insertion, deletion, update, O(1): find min(<code>min_vruntime</code> caches smallest value)</li>
<li>Update <code>vruntime</code> and <code>min_vruntime</code>: When task is added or removed, On every timer tick, context switch</li>
<li>Converting nice level to weight(): <code>static const int prio_to_weight[40] (sched.h)</code>, Nice level changes by 1-&gt;10% weight.(Pre-computed to avoid Floating point operations, Runtime overhead)(<strong>In the current implementation, each unit of difference in the nice values of two processes results in a factor of 1.25 in the degree to which the scheduler favors the higher priority process.</strong>, 来自sched和nice的的manual)<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&gt;   <span class="comment">// from https://elixir.bootlin.com/linux/v3.4/source/kernel/sched/sched.h#L804</span></span><br><span class="line">&gt;   <span class="comment">/*</span></span><br><span class="line"><span class="comment">&gt;    * Nice levels are multiplicative, with a gentle 10% change for every</span></span><br><span class="line"><span class="comment">&gt;    * nice level changed. I.e. when a CPU-bound task goes from nice 0 to</span></span><br><span class="line"><span class="comment">&gt;    * nice 1, it will get ~10% less CPU time than another CPU-bound task</span></span><br><span class="line"><span class="comment">&gt;    * that remained on nice 0.</span></span><br><span class="line"><span class="comment">&gt;    *</span></span><br><span class="line"><span class="comment">&gt;    * The "10% effect" is relative and cumulative: from _any_ nice level,</span></span><br><span class="line"><span class="comment">&gt;    * if you go up 1 level, it's -10% CPU usage, if you go down 1 level</span></span><br><span class="line"><span class="comment">&gt;    * it's +10% CPU usage. (to achieve that we use a multiplier of 1.25.</span></span><br><span class="line"><span class="comment">&gt;    * If a task goes up by ~10% and another task goes down by ~10% then</span></span><br><span class="line"><span class="comment">&gt;    * the relative distance between them is ~25%.)</span></span><br><span class="line"><span class="comment">&gt;    */</span></span><br><span class="line">&gt;   <span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">int</span> prio_to_weight[<span class="number">40</span>] = &#123;</span><br><span class="line">&gt;    <span class="comment">/* -20 */</span>     <span class="number">88761</span>,     <span class="number">71755</span>,     <span class="number">56483</span>,     <span class="number">46273</span>,     <span class="number">36291</span>,</span><br><span class="line">&gt;    <span class="comment">/* -15 */</span>     <span class="number">29154</span>,     <span class="number">23254</span>,     <span class="number">18705</span>,     <span class="number">14949</span>,     <span class="number">11916</span>,</span><br><span class="line">&gt;    <span class="comment">/* -10 */</span>      <span class="number">9548</span>,      <span class="number">7620</span>,      <span class="number">6100</span>,      <span class="number">4904</span>,      <span class="number">3906</span>,</span><br><span class="line">&gt;    <span class="comment">/*  -5 */</span>      <span class="number">3121</span>,      <span class="number">2501</span>,      <span class="number">1991</span>,      <span class="number">1586</span>,      <span class="number">1277</span>,</span><br><span class="line">&gt;    <span class="comment">/*   0 */</span>      <span class="number">1024</span>,       <span class="number">820</span>,       <span class="number">655</span>,       <span class="number">526</span>,       <span class="number">423</span>,</span><br><span class="line">&gt;    <span class="comment">/*   5 */</span>       <span class="number">335</span>,       <span class="number">272</span>,       <span class="number">215</span>,       <span class="number">172</span>,       <span class="number">137</span>,</span><br><span class="line">&gt;    <span class="comment">/*  10 */</span>       <span class="number">110</span>,        <span class="number">87</span>,        <span class="number">70</span>,        <span class="number">56</span>,        <span class="number">45</span>,</span><br><span class="line">&gt;    <span class="comment">/*  15 */</span>        <span class="number">36</span>,        <span class="number">29</span>,        <span class="number">23</span>,        <span class="number">18</span>,        <span class="number">15</span>,</span><br><span class="line">&gt;   &#125;;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</blockquote>
</li>
</ul>
<blockquote>
<ul>
<li>Hierarchical, modular scheduler <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt;    <span class="class"><span class="keyword">class</span> = <span class="title">sched_class_highest</span>;</span></span><br><span class="line">&gt;    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">&gt;        p = class-&gt;pick_next_task(rq);</span><br><span class="line">&gt;        <span class="keyword">if</span> (p)</span><br><span class="line">&gt;            <span class="keyword">return</span> p;</span><br><span class="line">&gt;       <span class="comment">/*</span></span><br><span class="line"><span class="comment">&gt;        * Will never be NULL as the idle class always</span></span><br><span class="line"><span class="comment">&gt;        * returns a non-NULL p:</span></span><br><span class="line"><span class="comment">&gt;        */</span></span><br><span class="line">&gt;        <span class="class"><span class="keyword">class</span> = <span class="title">class</span>-&gt;<span class="title">next</span>;</span></span><br><span class="line">&gt;    &#125;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</blockquote>
<blockquote>
<p>Ref: <a href="https://doc.opensuse.org/documentation/leap/tuning/html/book.sle.tuning/cha.tuning.taskscheduler.html" target="_blank" rel="noopener">SUSE-doc-Tuning the Task Scheduler</a></p>
<p>sched_latency_ns<br>Targeted preemption latency for CPU bound tasks. Increasing this variable increases a CPU bound task’s timeslice. A task’s timeslice is its weighted fair share of the scheduling period:</p>
<p>timeslice = scheduling period * (task’s weight/total weight of tasks in the run queue)</p>
<p>The task’s weight depends on the task’s nice level and the scheduling policy. Minimum task weight for a SCHED_OTHER task is 15, corresponding to nice 19. The maximum task weight is 88761, corresponding to nice -20.</p>
<p>Timeslices become smaller as the load increases. When the number of runnable tasks exceeds sched_latency_ns/sched_min_granularity_ns, the slice becomes number_of_running_tasks * sched_min_granularity_ns. Prior to that, the slice is equal to sched_latency_ns.</p>
<blockquote>
<p>sched_min_granularity_ns</p>
<p>Minimal preemption granularity for CPU bound tasks. See sched_latency_ns for details. The default value is 4000000 (ns).</p>
</blockquote>
<p>This value also specifies the maximum amount of time during which a sleeping task is considered to be running for entitlement calculations. Increasing this variable increases the amount of time a waking task may consume before being preempted, thus increasing scheduler latency for CPU bound tasks. The default value is 6000000 (ns).</p>
</blockquote>
<h4 id="Real-time-scheduling"><a href="#Real-time-scheduling" class="headerlink" title="Real-time scheduling"></a>Real-time scheduling</h4><blockquote>
<ul>
<li>Linux has soft real-time scheduling: No hard real-time guarantees</li>
<li>All real-time processes are higher priority than any conventional processes</li>
<li>Processes with priorities [0, 99] are real-time</li>
<li>Process can be converted to real-time via sched_setscheduler system call </li>
<li>First-in, first-out: SCHED_FIFO: Static priority, Process is only preempted for a higher-priority process, No time quanta; it runs until it blocks or yields voluntarily, RR within same priority level</li>
<li>Round-robin: SCHED_RR: As above but with a time quanta</li>
<li>Normal processes have SCHED_NORMAL scheduling policy</li>
</ul>
</blockquote>
<h4 id="Multiprocessor-scheduling"><a href="#Multiprocessor-scheduling" class="headerlink" title="Multiprocessor scheduling"></a>Multiprocessor scheduling</h4><blockquote>
<ul>
<li>Per-CPU runqueue</li>
<li>Possible for one processor to be idle while others have jobs waiting in their run queues</li>
<li>Periodically, rebalance runqueues</li>
<li>Migration threads move processes from one runque to another</li>
<li>The kernel always locks runqueues in the same order for deadlock prevention</li>
</ul>
</blockquote>
<h4 id="Adjusting-priority"><a href="#Adjusting-priority" class="headerlink" title="Adjusting priority"></a>Adjusting priority</h4><blockquote>
<ul>
<li>Goal: dynamically increase priority of interactive process</li>
<li>How to determine interactive? Sleep ratio, Mostly sleeping: I/O bound, Mostly running: CPU bound</li>
</ul>
</blockquote>
<h4 id="misc"><a href="#misc" class="headerlink" title="misc"></a>misc</h4><ul>
<li>Scheduling policies(Ref: <a href="https://www.kernel.org/doc/Documentation/scheduler/sched-design-CFS.txt" target="_blank" rel="noopener">Scheduling policies</a>)<blockquote>
<ol start="5">
<li>Scheduling policies</li>
</ol>
<p>CFS implements three scheduling policies:</p>
<ul>
<li><p>SCHED_NORMAL (traditionally called SCHED_OTHER): The scheduling<br>policy that is used for regular tasks.</p>
</li>
<li><p>SCHED_BATCH: Does not preempt nearly as often as regular tasks<br>would, thereby allowing tasks to run longer and make better use of<br>caches but at the cost of interactivity. This is well suited for<br>batch jobs.</p>
</li>
<li><p>SCHED_IDLE: This is even weaker than nice 19, but its not a true<br>idle timer scheduler in order to avoid to get into priority<br>inversion problems which would deadlock the machine.</p>
</li>
</ul>
<p>SCHED_FIFO/_RR are implemented in sched/rt.c and are as specified by<br>POSIX.</p>
</blockquote>
</li>
<li><p>SCHEDULING CLASSES</p>
<blockquote>
<p>The new CFS scheduler has been designed in such a way to introduce “Scheduling<br>Classes,” an extensible hierarchy of scheduler modules.  These modules<br>encapsulate scheduling policy details and are handled by the scheduler core<br>without the core code assuming too much about them.</p>
<p>sched/fair.c implements the CFS scheduler described above.</p>
<p>sched/rt.c implements SCHED_FIFO and SCHED_RR semantics, in a simpler way than<br>the previous vanilla scheduler did.  It uses 100 runqueues (for all 100 RT<br>priority levels, instead of 140 in the previous scheduler) and it needs no<br>expired array.</p>
<p>Scheduling classes are implemented through the sched_class structure, which<br>contains hooks to functions that must be called whenever an interesting event<br>occurs.</p>
</blockquote>
</li>
<li><p>Linux有两种不同的优先级范围</p>
<ul>
<li>nice值：从-20到19，越大优先级越低。所有unix系统的标准化概念，但是不同unix系统的调度算法不同，所以nice值的运用方式也不同。<code>ps -el</code>中<code>NI</code>那一列就是进程对应的nice值</li>
<li>实时优先级：从0到99，越大优先级越高。任何实时进程的优先级都高于普通进程，也就是实时优先级跟nice值是两个不相交的范畴。<code>ps -eo stat,uid,pid,ppid,rtprio,time,comm</code>中，<code>rtprio</code>就是实时优先级，如果是<code>-</code>则说明不是实时进程</li>
</ul>
</li>
<li>nice value（来自sched和nice的的manual）<blockquote>
<ul>
<li><strong>It affects the scheduling of SCHED_OTHER and SCHED_BATCH (see below) processes.</strong> </li>
<li>The nice value can be modified using nice(2), setpriority(2), or sched_setattr(2). </li>
<li><strong>According to POSIX.1, the nice value is a per-process attribute</strong>; that is, the threads in a process should share a nice value. However, <strong>on Linux, the nice value is a per-thread attribute</strong>: different threads in the same process may have different nice values. </li>
<li>The range of the nice value varies across UNIX systems. <strong>On modern Linux, the range is -20 (high priority) to +19 (low priority)</strong>. On some other systems, the range is -20..20. Very early Linux kernels (Before Linux 2.0) had the range -infinity..15. </li>
<li>The degree to which the nice value affects the relative scheduling of SCHED_OTHER processes likewise varies across UNIX systems and across Linux kernel versions. </li>
<li>With the advent of the <strong>CFS scheduler</strong> in kernel 2.6.23, Linux adopted an algorithm that <strong>causes relative differences in nice values to have a much stronger effect</strong>. </li>
<li><strong>In the current implementation, each unit of difference in the nice values of two processes results in a factor of 1.25 in the degree to which the scheduler favors the higher priority process.</strong> This causes very low nice values (+19) to truly provide little CPU to a process whenever there is any other higher priority load on the system, and makes high nice values (-20) deliver most of the CPU to applications that require it (e.g., some audio applications). </li>
<li>On Linux, the RLIMIT_NICE resource limit can be used to define a limit to which an unprivileged process’s nice value can be raised; see setrlimit(2) for details. </li>
<li>Traditionally, only a privileged process could lower the nice value (i.e., set a higher priority). However, since Linux 2.6.12, an unprivileged process can decrease the nice value of a target process that has a suitable RLIMIT_NICE soft limit; see getrlimit(2) for details.</li>
</ul>
</blockquote>
</li>
</ul>
<h3 id="进程状态"><a href="#进程状态" class="headerlink" title="进程状态"></a>进程状态</h3><ul>
<li>来自<em>linux内核设计与实现</em></li>
<li><code>TASK_RUNNING</code>：进程是可执行的，可能正在执行，或在运行队列中等待执行。这是进程在用户空间中执行的唯一可能状态。内核空间中正在执行的进程也是这种状态</li>
<li><code>TASK_INTERRUPTIBLE</code>：进程正在睡眠（也就是被阻塞），到达某些条件达成，一旦条件达成，内核就会把进程状态设置为RUNNING。处于此状态的进程会因为接收到信号而提前被唤醒并随时准备投入运行</li>
<li><code>TASK_UNINTERRUPTIBLE</code>：与<code>TASK_INTERRUPTIBLE</code>的差别在于，就算接受到信号也不会被唤醒或准备投入运行。通常在进程必须在等待时不受干扰或等待的事件很快就会发生时出现（比如这个任务正在进行重要的操作，甚至可能持有一个信号量）。因为不对信号做响应，所以较之可中断的状态，用的较少。（ps中看到的<code>D</code>状态的进程就是这种状态）</li>
<li><code>__TASK_TRACED</code>：被其他进程跟踪的进程，比如通过ptrace对调试程序进行跟踪</li>
<li><code>__TASK_STOPPED</code>：进程停止执行，没有投入运行也不能投入运行。发生在接受到<code>SIGSTOP</code>，<code>SIGTSTP</code>，<code>SIGTTIN</code>，<code>SIGTTOU</code>信号时，调试期间受到任何信号也会使得进程进入这状态</li>
<li>转换图见书P24(41)</li>
<li>Ref: ps manual <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">the state of a process:</span><br><span class="line">        D    uninterruptible sleep (usually IO)</span><br><span class="line">        I    Idle kernel thread</span><br><span class="line">        R    running or runnable (on run queue)</span><br><span class="line">        S    interruptible sleep (waiting for an event to complete)</span><br><span class="line">        T    stopped by job control signal</span><br><span class="line">        t    stopped by debugger during the tracing</span><br><span class="line">        W    paging (not valid since the 2.6.xx kernel)</span><br><span class="line">        X    dead (should never be seen)</span><br><span class="line">        Z    defunct (&quot;zombie&quot;) process, terminated but not reaped by its parent</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="僵尸进程、孤儿进程"><a href="#僵尸进程、孤儿进程" class="headerlink" title="僵尸进程、孤儿进程"></a>僵尸进程、孤儿进程</h3><ul>
<li>子进程的父进程终止后，成为孤儿进程，init（pid为1，所有进程的祖先）会接管孤儿进程，所以判断父进程是否终止的方法可以是检查getppid是否返回<code>1</code>（前提是这个子进程原本的父进程不是init）</li>
<li>系统允许父进程在子进程终止后还去执行<code>wait</code>，以确定子进程是如何终止的。这是通过把子进程转为僵尸进程来处理的，僵尸进程释放了该该进程持有的大部分资源，唯一保留的是内核中的进程表中的一条记录（包含pid、终止状态、资源使用数据等）。僵尸进程无法被<code>SIGKILL</code>杀死（SIGKILL、SIGSTOP信号无法被捕获和忽略）</li>
<li>父进程调用<code>wait</code>之后，内核将删除僵尸进程，如果父进程没有执行<code>wait</code>就退出，init将接管子进程并自动调用<code>wait</code></li>
<li>如果父进程没有退出，而又没有<code>wait</code>子进程，那么就可能导致僵尸进程填满内核进程表，从而阻碍新进程的创建。将他们移除的唯一方法是：杀死父进程（或是等待父进程终止）从而init会<code>wait</code></li>
<li>父进程<code>wait</code>的方式<ul>
<li>父进程不带<code>WNOHANG</code>标志调用<code>wait</code></li>
<li>父进程带有<code>WNOHANG</code>标志轮询</li>
<li>为SIGCHILD建立handler（默认是忽略）。需要在handler内部带<code>WNOHANG</code>不断调用<code>wait</code>以避免两个问题：调用信号Handler时，会阻塞引发该handler的信号；同一个信号不排队</li>
<li>应该在创建任何子进程之前就设置好Handler，因为在设置Handler时，如果已有子进程终止，那么有的系统会立刻产生SIGCHILD信号，有的不会</li>
</ul>
</li>
</ul>
<h3 id="进程内存布局"><a href="#进程内存布局" class="headerlink" title="进程内存布局"></a>进程内存布局</h3><ul>
<li>共享库的虚拟地址是随着运行确定的，使用<code>pmap</code>拿地址布局可以看到，两次运行，共享库的地址布局不一样</li>
<li><code>ldd</code>显示的lib地址也是随着ldd的不同调用而改变的<blockquote>
<p>Be  aware that in some circumstances (e.g., where the program specifies an ELF interpreter other than ld-linux.so), some versions of ldd may attempt to obtain the dependency information by attempting to directly execute the program, which may lead to the execution of whatever code is  defined  in the  program’s ELF interpreter, and perhaps to execution of the program itself</p>
</blockquote>
</li>
</ul>
<h3 id="MISC"><a href="#MISC" class="headerlink" title="MISC"></a>MISC</h3><ul>
<li>识别僵尸进程<code>ps -ef | grep &quot;defunct&quot;</code></li>
</ul>
<h3 id="SO-REUSEPORT"><a href="#SO-REUSEPORT" class="headerlink" title="SO_REUSEPORT"></a><code>SO_REUSEPORT</code></h3><blockquote>
<p><a href="https://lwn.net/Articles/542629/" target="_blank" rel="noopener">引用自</a></p>
<ul>
<li>The new socket option allows multiple sockets on the same host to bind to the same port, and is intended to improve the performance of multithreaded network server applications running on top of multicore systems.</li>
<li>So long as the first server sets this option before binding its socket, then any number of other servers can also bind to the same port if they also set the option beforehand</li>
<li>The requirement that the first server must specify this option prevents port hijacking—the possibility that a rogue application binds to a port already used by an existing server in order to capture (some of) its incoming connections or datagrams.</li>
<li>To prevent unwanted processes from hijacking a port that has already been bound by a server using SO_REUSEPORT, all of the servers that later bind to that port must have an effective user ID that matches the effective user ID used to perform the first bind on the socket. </li>
<li>The second of the traditional approaches used by multithreaded servers operating on a single port is to have all of the threads (or processes) perform an accept() call on a single listening socket in a simple event loop of the form:<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;    <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">&gt;        new_fd = accept(...);</span><br><span class="line">&gt;        process_connection(new_fd);</span><br><span class="line">&gt;    &#125;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</blockquote>
<blockquote>
<p>  The problem with this technique, as Tom pointed out, is that when multiple threads are waiting in the accept() call, wake-ups are not fair, so that, under high load, incoming connections may be distributed across threads in a very unbalanced fashion</p>
<ul>
<li>the SO_REUSEPORT implementation distributes connections evenly across all of the threads (or processes) that are blocked in accept() on the same port.</li>
<li>SO_REUSEPORT can be used with both TCP and UDP sockets.</li>
<li>Tom noted that the traditional SO_REUSEADDR socket option already allows multiple UDP sockets to be bound to, and accept datagrams on, the same UDP port. However, by contrast with SO_REUSEPORT, SO_REUSEADDR does not prevent port hijacking and does not distribute datagrams evenly across the receiving threads.</li>
</ul>
</blockquote>
<h3 id="PTHREAD-STACK-MIN"><a href="#PTHREAD-STACK-MIN" class="headerlink" title="PTHREAD_STACK_MIN"></a><code>PTHREAD_STACK_MIN</code></h3><blockquote>
<p>Ref: <a href="https://docs.oracle.com/cd/E19120-01/open.solaris/816-5137/attrib-45427/index.html" target="_blank" rel="noopener">Setting the Stack Size</a></p>
<ul>
<li>The size attribute defines the size of the stack (in bytes) that the system allocates. The size should not be less than the system-defined minimum stack size. See About Stacks for more information.</li>
<li>size contains the number of bytes for the stack that the new thread uses. If size is zero, a default size is used. In most cases, a zero value works best.<br>-PTHREAD_STACK_MIN is <strong>the amount of stack space that is required to start a thread</strong>. This stack space does not take into consideration the threads routine requirements that are needed to execute application code.</li>
</ul>
</blockquote>
<h3 id="IO"><a href="#IO" class="headerlink" title="IO"></a>IO</h3><ul>
<li>慢速syscall被信号中断时，已经read、write部分数据的syscall的处理：POSIX2001版是规定为成功返回，返回已read、write的字节数</li>
<li>POSIX.1要求只有中断信号的<code>SA_RESTART</code>标志有效时，才重启。不同厂商的处理方式不同</li>
<li>所有的IO设备都被模型化为文件，所有的输入输出都可以被当做相应文件的读和写来处理，这种将设备映射成文件的方式，允许Linux内核引用一个简单、低级的应用接口（Unix IO），这使得所有的输入输出都能以一种统一且一致的方式进行</li>
<li>异步IO。要注意区分信号驱动IO，后者以前也叫AIO<blockquote>
<p>The current Linux POSIX AIO implementation is provided <strong>in user space by glibc</strong>. <strong>This has a number of limitations, most notably that maintaining mul‐ tiple threads to perform I/O operations is expensive and scales poorly</strong>. Work has been in progress for some time <strong>on a kernel state-machine-based implementation of asynchronous I/O (see io_submit(2), io_setup(2), io_cancel(2), io_destroy(2), io_getevents(2))</strong>, but this implementation hasn’t yet matured to the point where the POSIX AIO implementation can be completely reimplemented using the kernel system calls.</p>
</blockquote>
</li>
</ul>
<h3 id="网络编程"><a href="#网络编程" class="headerlink" title="网络编程"></a>网络编程</h3><ul>
<li>因特网的socket地址存放在<code>sockaddr_in</code>的struct中</li>
<li>connect、bind、accept函数需要接受各种类型的socket地址结构（不仅仅是因特网socket），所以其要求大家都强转成<code>socketaddr</code>给他</li>
<li>socket函数才能一个socketFD，可以硬编码<code>socket(AF_INET, SOCK_STREAM, 0)</code>，其返回的fd仅仅是部分打开，还不能用于读写</li>
<li>客户端使用connect函数来完成三次握手</li>
<li><code>socket()</code>：返回一个socketFd，这是一个主动套接字</li>
<li><code>bind()</code><ul>
<li>把一个本地协议地址赋予一个socket，对于ip协议，就是32bit的ipv4地址或128bit的ipv6地址与16bit的tcp或udp端口号的组合</li>
<li>调用bind时，可以指定一个端口号和（或）一个ip地址，也可以都不指定</li>
</ul>
</li>
<li><code>listen()</code>：把<code>socket()</code>创建的主动套接字转为监听套接字</li>
<li>在大多数Linux架构上（除了Alpha和IA-64），所有这些socket系统调用实际上被实现成了通过单个系统调用socketcall()进行多路复用的库函数</li>
<li>socket中的一方调用close之后，当对等应用程序试图从连接的另一端读取数据时将会收到文件结束（<strong>当所有缓冲数据都被读取之后</strong>）</li>
<li>如果connect()失败并且希望重新进行连接，那么SUSv3规定完成这个任务的可移植的方法是关闭这个socket，创建一个新socket，在该新socket上重新进行连接</li>
<li>如果多个文件描述符引用了同一个socket，那么当所有描述符被关闭之后（使用<code>close()</code>）连接就会终止</li>
<li><blockquote>
<p><code>AF_INET</code>需经过多个协议层的编解码，消耗系统cpu，并且数据传输需要经过网卡，受到网卡带宽的限制。AF_UNIX数据到达内核缓冲区后，由内核根据指定路径名找到接收方socket对应的内核缓冲区，直接将数据拷贝过去，不经过协议层编解码，节省系统cpu，并且不经过网卡，因此不受网卡带宽的限制。AF_UNIX的传输速率远远大于AF_INET(<a href="https://blog.csdn.net/sandware/article/details/40923491" target="_blank" rel="noopener">Ref from</a>)</p>
</blockquote>
</li>
</ul>
<h4 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h4><ul>
<li><p>epoll支持水平触发和边缘触发</p>
<ul>
<li>水平触发：能在FD上以非阻塞的方式执行I/O操作（poll、select提供的也是这个）</li>
<li><p>边缘触发</p>
<ul>
<li><p>自从上一次调用<code>epoll_wait</code>后FD上是否已经有I/O活动（或者是FD被打开，如果之前没有调用的话），语义上类似信号驱动I/O，如果有多个I/O事件发生，epoll会把他们合并成一次单独的通知（信号驱动上可能会产生多个信号）</p>
</li>
<li><p>可以减少syscall的次数</p>
<blockquote>
<p>在eventloop类型(包括各类fiber/coroutine)的程序中, 处理逻辑和epoll_wait都在一个线程, ET相比LT没有太大的差别. 反而由于LT醒的更频繁, 可能时效性更好些. 在老式的多线程RPC实现中, 消息的读取分割和epoll_wait在同一个线程中运行, 类似上面的原因, ET和LT的区别不大.<br>但在更高并发的RPC实现中, 为了对大消息的反序列化也可以并行, 消息的读取和分割可能运行和epoll_wait不同的线程中, 这时ET是必须的, 否则在读完数据前, epoll_wait会不停地无谓醒来.</p>
<p><a href="https://www.zhihu.com/question/20502870/answer/142303523" target="_blank" rel="noopener">引用自</a></p>
</blockquote>
</li>
<li><p>程序基本框架如下</p>
<ul>
<li>所有待监视的FD都设置为非阻塞</li>
<li>通过<code>epoll_ctl</code>建立epoll interest list</li>
<li>使用如下循环处理IO事件<ul>
<li>用<code>epoll_wait</code>取得ready的FD list</li>
<li>针对每一个处于ready的FD，不断调用IO syscall，直到返回<code>EAGAIN</code>或<code>EWOULDBLOCK</code></li>
</ul>
</li>
<li>解决饥饿的方法<ul>
<li>应用程序自己维护一个list，该list存储到目前为止的所有ready FD（如果某个FD返回<code>EAGAIN</code>或<code>EWOULDBLOCK</code>，则移出去）</li>
<li>每次都调用<code>epoll_wait</code>去监视并添加ready FD到list中。如果list中已经有FD，则这次监视的timeout（应该指的是<code>epoll_wait</code>的timeout参数）应该为0或较小的正数。这样子就不用在<code>epoll_wait</code>上花太多时间，可以进行IO</li>
<li>对于list上的FD，可以使用round-robin方式去循环处理，而不是每次从<code>epoll_wait</code>返回后都从list头开始处理</li>
<li>相对之下，使用水平触发时，因为我们只是在ready 的FD上做一些IO而已（不是循环到不能读为止），所以不会有饥饿问题。（英文原文说的是blocking 的FD，译文说的是非阻塞，我觉得也是非阻塞比较合适，因为如果阻塞那么一旦没东西读了，会不会阻塞在那里呢？还是说只要读了一点东西，然后接下来不能读，就立刻可以返回）</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>核心数据结构称为epoll实例，与epoll_fd关联，是内核数据结构的句柄。这些内核数据结构实现了两个目的</p>
<ul>
<li>interest list</li>
<li>ready list（前者的子集）</li>
</ul>
</li>
<li><p><code>epoll_create</code>：创建epoll实例，size参数已废弃。<code>epoll_create1</code>去掉了该参数并且可设置flags，目前只支持<code>EPOLL_CLOEXEC</code></p>
<blockquote>
<p>close-on-exec<br>which causes the file descriptor to be  automatically (and atomically) closed when any of the exec-family functions succeed.<br>This is useful to keep from leaking your file descriptors to random programs run by e.g. <code>system()</code>.</p>
</blockquote>
</li>
<li><p><code>epoll_ctl</code></p>
<ul>
<li>fd参数（第三个参数）可以是pipe、FIFO、socket、POSIX消息队列、inotify实例、终端、设备、另一个epoll实例的fd（可以用于建立层次关系），不能是普通文件或目录的FD（EPERM）</li>
<li>In a multithreaded program, it is possible for one thread to use <code>epoll_ctl</code> to add file descriptors to the interest list of an epoll instance that is already being monitored by epoll_wait() in another thread. These changes to the interest list will be taken into account immediately, and the epoll_wait() call will return readiness information about the newly added file descriptors. </li>
</ul>
</li>
<li><p><code>EPOLLONESHOT</code>：在下一次epoll_wait返回该FD后，该FD在兴趣列表中被标记为非激活状态，可以用<code>EPOLL_CTL_MOD</code>重新激活</p>
</li>
<li><p><code>max_user_watcher</code>：每个注册到epoll实例上的FD都会占用一小段不能被交换的内核内存空间。这个参数用于定义可以注册到epoll实例上的FD总数。<code>/proc/sys/fs/epoll/max_user_watches</code></p>
</li>
<li><p><code>epoll_wait</code></p>
<ul>
<li><p>返回后，需要检查<code>EINTR</code>，如果在执行期间被一个信号打断，然后又通过SIGCONT信号恢复，就可能出现这个错误</p>
</li>
<li><p><code>EPOLLHUP</code></p>
<blockquote>
<p> Note that when reading from a channel such as a pipe or a stream socket, this event merely indicates that the peer  closed  its  end  of  the channel.  Subsequent reads from the channel will return 0 (end of file) <strong>only after all outstanding data in the channel has been consumed.</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="keyword">if</span>(evlist[j].events &amp; EPOLLIN) &#123;</span><br><span class="line">&gt;     <span class="comment">// do read</span></span><br><span class="line">&gt; &#125;<span class="keyword">else</span> <span class="keyword">if</span>(evlist[j].events &amp; (EPOLLHUP | EPOLLERR)) &#123;</span><br><span class="line">&gt;     <span class="comment">// close fd </span></span><br><span class="line">&gt; &#125;</span><br><span class="line">&gt; <span class="comment">//  After the epoll_wait(), EPOLLIN and EPOLLHUP may both have been set. But we'll only get here, and thus close the file descriptor, if EPOLLIN was not set. This ensures that all outstanding input (possibly more than MAX_BUF bytes) is consumed (by further loop iterations) before the file descriptor is closed.</span></span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p><code>EPOLLHUP</code>和<code>EPOLLERR</code>会出现在FIFO对端关闭或终端挂起时出现</p>
</li>
</ul>
</li>
<li>epoll的语义<ul>
<li>创建epoll实例时，内核在内存中创建一个新的i-node并打开<strong>文件描述</strong>（file descriptor：一个打开的文件的上下文信息，内核的数据结构）</li>
<li>随后在调用进程中为打开的这个文件描述分配一个新的<strong>文件描述符</strong>（这就是用户空间的应用程序操作这个file descriptor的句柄）</li>
<li>同epoll实例的insterest list相关联的是打开的<strong>文件描述</strong>，而不是<strong>文件描述符</strong>。所以可以使用dup复制该描述符，fork也可以，因为子进程复制了父进程的epoll描述符。复制后的描述符指向相同的<strong>文件描述</strong></li>
<li>如果一个<strong>文件描述</strong>是epoll insterest list的成员，那么在这个<strong>文件描述</strong>的所有描述符都关闭后，这个<strong>文件描述</strong>会自动从epoll 的interest list中移除</li>
<li>所以如果某个fd A被复制（复制的那一个叫fd B），然后关闭该fd A，但是epoll_wait还是会在该<strong>文件描述</strong>就绪后返回fd A</li>
</ul>
</li>
<li>epoll vs select vs poll<ul>
<li>每次调用select、poll，内核必须检查所有在调用中指定的FD。epoll只需要在FD就绪时将其加入ready list，然后<code>epoll_wait</code>去fetch这些FD就行</li>
<li>调用select、poll时，我们传递一个标记了所有待监视的FD的数据结构给内核，返回时，内核将所有标记为ready的FD的数据结构在传给我们。epoll则使用<code>epoll_ctl</code>在内核空间建立数据结构，之后的<code>epoll_wait</code>不需要传递数据结构，返回的也只是ready的FD</li>
<li>epoll的性能会随着发生I/O事件的数量而线性变化，所以适用于需要监视大量FD但是大部分处于空闲状态</li>
</ul>
</li>
<li>epoll与信号<ul>
<li><code>epoll_wait</code>的过程中是会因为SIGINT而返回，errno为EINTR的</li>
<li>如果使用了信号，应该使用<code>epoll_pwait</code>来避免race condition</li>
</ul>
</li>
<li><blockquote>
<ul>
<li>值得一提的时，epoll的效率在某些情况下比select或者poll要低，这个是曾经做过测试的。具体的业务场景就是：几乎所有连接都处于活跃状态，并且有频繁的业务数据发送和接受，这个时候select或者poll的能力要强于epoll。下面贴一张比较久远的测试数据表格，可以看到这个现象。一个用select实现的echo server，传输的数据量是52B一次的小报文。 (<a href="http://zbo.space/2016/05/24/netio/" target="_blank" rel="noopener">Ref</a>)</li>
<li><p>select</p>
<p> |连接数量|cpu(%)|一次回射平均延时(μs)|<br> |:-:|:-:|:-:|<br> |100|94.5|1394|<br> |500|95|9507|<br> |1000|95|19852|</p>
</li>
<li><p>epoll</p>
<p> |连接数量|cpu(%)|一次回射平均延时(μs)|<br> |:-:|:-:|:-:|<br> |100|93|1930|<br> |500|93|11120|<br> |1000|95|23857|</p>
</li>
<li>(或许是因为使用了中断，所以不如轮询快？另外，select是数组，epoll应该是链表（？）所以cache miss高？不过听说kqueue可以合并中断，还可以把中断改成轮询)</li>
<li>原理其它答案讲得差不多了，我就补一句，从kernel层面将，事件产生有可能不是由硬件中断触发的，在一定情况下kernel的确会轮询，因为响应硬件中断是一个成本比较高的操作。以网卡为例，当数据量很少的时候，每来一个数据包网卡都回产生一个中断，kernel响应这个中断，从网卡缓冲区中读出数据放进协议栈处理，当满足一定条件时，kernel回调用户代码，这里的“回调”一般情况下是指从一个kernel syscall中返回(在此之前用户代码一直处于block状态)。当数据量很大时，每个包都产生一个中断就划不来了，此时kernel可以启动interrupt coalescing机制，让网卡做中断合并，也就是说来足够多的数据包或者等待一个timeout才会产生一个中断，kernel在响应中断时会把所有数据一起读出来处理，这样可以有效的降低中断次数。当数据量更大时，网卡缓冲区里几乎总是有未处理的数据，此时kernel干脆会禁掉网卡的中断，切换到轮询处理的模式，说白了就是跑一个忙循环不停地读网卡缓冲区里的数据，这样综合开销更低。<br>作者：徐辰<br>链接：<a href="https://www.zhihu.com/question/20122137/answer/54153089" target="_blank" rel="noopener">https://www.zhihu.com/question/20122137/answer/54153089</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</li>
</ul>
</blockquote>
</li>
</ul>
<h3 id="惊群"><a href="#惊群" class="headerlink" title="惊群"></a>惊群</h3><ul>
<li><blockquote>
<p>很多个进程都block在server socket的accept()，一但有客户端进来，所有进程的accept()都会返回，但是只有一个进程会读到数据，就是惊群。实际上现在的Linux内核实现中不会出现惊群了，只会有一个进程被唤醒（Linux2.6内核）(<a href="https://www.zhihu.com/question/22756773/answer/22516222" target="_blank" rel="noopener">ref</a>)</p>
</blockquote>
</li>
<li><blockquote>
<p>为了确保只有一个进程（线程）得到资源，需要对资源操作进行加锁保护，加大了系统的开销。目前一些常见的服务器软件有的是通过锁机制解决的，比如 Nginx</p>
</blockquote>
</li>
<li><a href="https://www.zhihu.com/question/22756773/answer/545048210" target="_blank" rel="noopener">什么是惊群，如何有效避免惊群? - 滴滴云的回答 - 知乎</a></li>
</ul>
<h3 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h3><h4 id="top"><a href="#top" class="headerlink" title="top"></a>top</h4><ul>
<li><a href="http://ilinuxkernel.com/?p=869" target="_blank" rel="noopener">Ref</a>。影响load average值大小的直接因素是系统中活动的进程数。Linux的系统负载指运行队列的平均长度，也就是等待CPU的平均进程数。活动的进程数可以很直观表明系统负载情况。值越大，表明CPU上正在运行和待运行的进程数越多，也就是负载越大。查看loadAvg的方法：top、uptime、w、cat /proc/loadavg，是一分钟、五分钟、十五分钟</li>
<li>top的manual <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"> 2b. TASK and CPU States</span><br><span class="line">    This  portion  consists of a minimum of two lines.  In an SMP environ‐</span><br><span class="line">    ment, additional lines can reflect individual CPU state percentages.</span><br><span class="line"></span><br><span class="line">    Line 1 shows total tasks or threads, depending on  the  state  of  the</span><br><span class="line">    Threads-mode toggle.  That total is further classified as:</span><br><span class="line">        running; sleeping; stopped; zombie</span><br><span class="line"></span><br><span class="line">    Line  2  shows  CPU  state percentages based on the interval since the</span><br><span class="line">    last refresh.</span><br><span class="line"></span><br><span class="line">    As a default, percentages for these  individual  categories  are  dis‐</span><br><span class="line">    played.   Where two labels are shown below, those for more recent ker‐</span><br><span class="line">    nel versions are shown first.</span><br><span class="line">        us, user    : time running un-niced user processes</span><br><span class="line">        sy, system  : time running kernel processes</span><br><span class="line">        ni, nice    : time running niced user processes</span><br><span class="line">        id, idle    : time spent in the kernel idle handler</span><br><span class="line">        wa, IO-wait : time waiting for I/O completion</span><br><span class="line">        hi : time spent servicing hardware interrupts</span><br><span class="line">        si : time spent servicing software interrupts</span><br><span class="line">        st : time stolen from this vm by the hypervisor</span><br><span class="line"></span><br><span class="line">    In  the  alternate  cpu  states  display  modes,  beyond   the   first</span><br><span class="line">    tasks/threads  line,  an  abbreviated  summary  is shown consisting of</span><br><span class="line">    these elements（就是按了`t`键之后显示的内容）:</span><br><span class="line">                   a    b     c    d</span><br><span class="line">        %Cpu(s):  75.0/25.0  100[ ...</span><br><span class="line"></span><br><span class="line">    Where: a) is the combined us and ni percentage; b) is the sy  percent‐</span><br><span class="line">    age; c) is the total; and d) is one of two visual graphs of those rep‐</span><br><span class="line">    resentations.  See topic 4b. SUMMARY AREA Commands and the `t&apos; command</span><br><span class="line">    for additional information on that special 4-way toggle.</span><br><span class="line"></span><br><span class="line">2c. MEMORY Usage</span><br><span class="line">    This  portion  consists  of  two  lines  which  may  express values in</span><br><span class="line">    kibibytes (KiB) through exbibytes (EiB) depending on the scaling  fac‐</span><br><span class="line">    tor enforced with the `E&apos; interactive command.</span><br><span class="line"></span><br><span class="line">    As a default, Line 1 reflects physical memory, classified as:</span><br><span class="line">        total, free, used and buff/cache</span><br><span class="line"></span><br><span class="line">    Line 2 reflects mostly virtual memory, classified as:</span><br><span class="line">        total, free, used and avail (which is physical memory)</span><br><span class="line"></span><br><span class="line">    The  avail number on line 2 is an estimation of physical memory avail‐</span><br><span class="line">    able for starting new applications, without swapping.  Unlike the free</span><br><span class="line">    field,  it  attempts to account for readily reclaimable page cache and</span><br><span class="line">    memory slabs.  It is available on kernels 3.14,  emulated  on  kernels</span><br><span class="line">    2.6.27+, otherwise the same as free.</span><br><span class="line"></span><br><span class="line">    In  the  alternate memory display modes, two abbreviated summary lines</span><br><span class="line">    are shown consisting of these elements:</span><br><span class="line">                   a    b          c</span><br><span class="line">        GiB Mem : 18.7/15.738   [ ...</span><br><span class="line">        GiB Swap:  0.0/7.999    [ ...</span><br><span class="line"></span><br><span class="line">    Where: a) is the percentage used; b) is the total available; and c) is</span><br><span class="line">    one of two visual graphs of those representations.</span><br><span class="line"></span><br><span class="line">    In  the  case  of physical memory, the percentage represents the total</span><br><span class="line">    minus the estimated avail noted above.   The  `Mem&apos;  graph  itself  is</span><br><span class="line">    divided  between used and any remaining memory not otherwise accounted</span><br><span class="line">    for by avail.  See topic 4b. SUMMARY AREA Commands and the `m&apos; command</span><br><span class="line">    for additional information on that special 4-way toggle.</span><br><span class="line"></span><br><span class="line">    This table may help in interpreting the scaled values displayed:</span><br><span class="line">        KiB = kibibyte = 1024 bytes</span><br><span class="line">        MiB = mebibyte = 1024 KiB = 1,048,576 bytes</span><br><span class="line">        GiB = gibibyte = 1024 MiB = 1,073,741,824 bytes</span><br><span class="line">        TiB = tebibyte = 1024 GiB = 1,099,511,627,776 bytes</span><br><span class="line">        PiB = pebibyte = 1024 TiB = 1,125,899,906,842,624 bytes</span><br><span class="line">        EiB = exbibyte = 1024 PiB = 1,152,921,504,606,846,976 bytes</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="free"><a href="#free" class="headerlink" title="free"></a>free</h4>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">free  displays the total amount of free and used physical and swap memory</span><br><span class="line">in the system, as well as the buffers and caches used by the kernel.  The</span><br><span class="line">information  is  gathered by parsing /proc/meminfo. The displayed columns</span><br><span class="line">are:</span><br><span class="line"></span><br><span class="line">total  Total installed memory (MemTotal and SwapTotal in /proc/meminfo)</span><br><span class="line"></span><br><span class="line">used   Used memory (calculated as total - free - buffers - cache)</span><br><span class="line"></span><br><span class="line">free   Unused memory (MemFree and SwapFree in /proc/meminfo)</span><br><span class="line"></span><br><span class="line">shared Memory used (mostly) by tmpfs (Shmem in /proc/meminfo)</span><br><span class="line"></span><br><span class="line">buffers</span><br><span class="line">       Memory used by kernel buffers (Buffers in /proc/meminfo)</span><br><span class="line"></span><br><span class="line">cache  Memory used by the page cache and slabs (Cached  and  SReclaimable</span><br><span class="line">       in /proc/meminfo)</span><br><span class="line"></span><br><span class="line">buff/cache</span><br><span class="line">       Sum of buffers and cache</span><br><span class="line"></span><br><span class="line">available</span><br><span class="line">       Estimation of how much memory is available for starting new appli‐</span><br><span class="line">       cations, without swapping. Unlike the data provided by  the  cache</span><br><span class="line">       or  free fields, this field takes into account page cache and also</span><br><span class="line">       that not all reclaimable memory slabs will  be  reclaimed  due  to</span><br><span class="line">       items  being  in  use (MemAvailable in /proc/meminfo, available on</span><br><span class="line">       kernels 3.14, emulated on kernels 2.6.27+, otherwise the  same  as</span><br><span class="line">       free)</span><br></pre></td></tr></table></figure>
<ul>
<li>Buffers vs Cached(<a href="https://access.redhat.com/solutions/406773#diag" target="_blank" rel="noopener">Ref</a>, <a href="https://www.kernel.org/doc/Documentation/filesystems/proc.txt" target="_blank" rel="noopener">Ref</a>)<ul>
<li>Buffers: Memory in buffer cache, so relatively temporary storage for raw disk blocks. This shouldn’t get very large.</li>
<li>Cached: Memory in the pagecache (Diskcache and Shared Memory)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">  Buffers: Relatively temporary storage for raw disk blocks</span><br><span class="line">          shouldn&apos;t get tremendously large (20MB or so)</span><br><span class="line">  Cached: in-memory cache for files read from the disk (the</span><br><span class="line">          pagecache).  Doesn&apos;t include SwapCached</span><br><span class="line">SwapCached: Memory that once was swapped out, is swapped back in but</span><br><span class="line">          still also is in the swapfile (if memory is needed it</span><br><span class="line">          doesn&apos;t need to be swapped out AGAIN because it is already</span><br><span class="line">          in the swapfile. This saves I/O)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h4 id="vmstat"><a href="#vmstat" class="headerlink" title="vmstat"></a>vmstat</h4>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">FIELD DESCRIPTION FOR VM MODE</span><br><span class="line">   Procs</span><br><span class="line">       r: The number of runnable processes (running or waiting for run time).</span><br><span class="line">       b: The number of processes in uninterruptible sleep.</span><br><span class="line"></span><br><span class="line">   Memory</span><br><span class="line">       swpd: the amount of virtual memory used.</span><br><span class="line">       free: the amount of idle memory.</span><br><span class="line">       buff: the amount of memory used as buffers.</span><br><span class="line">       cache: the amount of memory used as cache.</span><br><span class="line">       inact: the amount of inactive memory.  (-a option)</span><br><span class="line">       active: the amount of active memory.  (-a option)</span><br><span class="line"></span><br><span class="line">   Swap</span><br><span class="line">       si: Amount of memory swapped in from disk (/s).</span><br><span class="line">       so: Amount of memory swapped to disk (/s).</span><br><span class="line"></span><br><span class="line">   IO</span><br><span class="line">       bi: Blocks received from a block device (blocks/s).</span><br><span class="line">       bo: Blocks sent to a block device (blocks/s).</span><br><span class="line"></span><br><span class="line">   System</span><br><span class="line">       in: The number of interrupts per second, including the clock.</span><br><span class="line">       cs: The number of context switches per second.</span><br><span class="line"></span><br><span class="line">   CPU</span><br><span class="line">       These are percentages of total CPU time.</span><br><span class="line">       us: Time spent running non-kernel code.  (user time, including nice time)</span><br><span class="line">       sy: Time spent running kernel code.  (system time)</span><br><span class="line">       id: Time spent idle.  Prior to Linux 2.5.41, this includes IO-wait time.</span><br><span class="line">       wa: Time spent waiting for IO.  Prior to Linux 2.5.41, included in idle.</span><br><span class="line">       st: Time stolen from a virtual machine.  Prior to Linux 2.6.11, unknown.</span><br></pre></td></tr></table></figure>
<ul>
<li>buff vs cache<blockquote>
<p><a href="http://tldp.org/LDP/sag/html/buffer-cache.html" target="_blank" rel="noopener">tldp-buffer-cache</a></p>
<ul>
<li>By reading the information from disk only once and then keeping it in memory until no longer needed, one can speed up all but the first read. This is called disk buffering, and the memory used for the purpose is called the buffer cache.</li>
<li>To make the most efficient use of real memory, Linux automatically uses all free RAM for buffer cache, but also automatically makes the cache smaller when programs need more memory. Under Linux, you do not need to do anything to make use of the cache, it</li>
</ul>
</blockquote>
</li>
</ul>
<h3 id="HugePage"><a href="#HugePage" class="headerlink" title="HugePage"></a>HugePage</h3><ul>
<li>好处<ul>
<li>增加TLB命中率</li>
<li>减小页表大小</li>
<li>如果可以把多级页表的级数减少，则可以减小查页表时间</li>
</ul>
</li>
<li><p>缺点</p>
<ul>
<li>有一些需要页对齐的场景那么为了对齐浪费的空间就比较多</li>
<li>页表提供的内存保护是以页为单位的</li>
<li>缺页时需要调入的东西增加</li>
<li>共享内存时需要共享整数个页那么大的块（我认为如此，因为是通过在页表中填入相同的物理页地址来共享内存的）</li>
<li>brk上调brk指针时，需要上调到页的边界，所以如果使用HugePage，会导致每次都分配很多虚拟内存（当然只要这些内存没有被读写，就不会分配物理内存）</li>
<li><p>Cache的命中率可能会降低，比如如果有的东西需要放在相邻的两个页上，那么4K页时，其实两个东西都可以缓存在L1，但是对于4M的页则不行</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>
<p> Model name:          Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz<br> L1d cache:           32K<br> L1i cache:           32K<br> L2 cache:            256K<br> L3 cache:            8192K</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>
</li>
<li><p>因为程序所占用的物理内存都需要在页表有记录，那么hugePage意味着小应用会占用更多内存</p>
</li>
<li>mmap<blockquote>
<p>on Linux, the mapping will be created at a nearby page boundary.<br>offset must be a multiple of the page size as returned by sysconf(_SC_PAGE_SIZE).</p>
</blockquote>
</li>
</ul>
</li>
<li><p>其他影响</p>
<ul>
<li>块（文件系统的一种抽象，文件系统的最小寻址单元，只能基于块来访问文件系统）不能比page大（This is an artificial constraint that could go away in the future），所以hugepage会使得块可以很大</li>
</ul>
</li>
</ul>
<h3 id="malloc"><a href="#malloc" class="headerlink" title="malloc"></a>malloc</h3><ul>
<li><p>调用并分配1GB的内存，是否物理内存就会少1G？一方面，CopyOnWrite，所以如果没有写，是不会的。另一方面，空闲链表</p>
</li>
<li><p>malloc的内存对齐</p>
<ul>
<li><blockquote>
<p>The malloc() and calloc() functions return a pointer to the allocated memory that is <strong>suitably aligned for any kind of variable</strong>.  (Ref from malloc’s man)</p>
</blockquote>
</li>
<li>在我的x86-64的机器上试了几次，返回的是16B对齐的内存 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"%p\n%p\n%p\n"</span>, <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">int</span>)), <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">char</span>)), <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">short</span>)));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 0x14bd260</span></span><br><span class="line"><span class="comment">// 0x14bd280</span></span><br><span class="line"><span class="comment">// 0x14bd2a0</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li>nginx在<code>core/ngx_palloc.c</code>的<code>ngx_create_pool</code>使用16中调用了<code>ngx_memalign</code>，<code>ngx_memalign</code>的一个实现是直接使用<code>malloc</code></li>
</ul>
</li>
<li><p>堆内存边界被称为<code>program break</code>，使用<code>brk</code>和<code>sbrk</code>可以调整。一开始<code>program break</code>位于未初始化的数据段末尾之后。使用<code>brk</code>等抬高<code>program break</code>后，物理内存页尚未分配，内核会在进程首次此试图访问这些虚拟内存地址时自动分配新的物理内存页</p>
</li>
<li><p>虚拟内存以页为单位进行分配，所以调用brk指定的end addr实际上会round up到下一个page boundary</p>
<blockquote>
<p>The brk() system call sets the program break to the location specified by <code>end_data_segment</code>. Since virtual memory is allocated in units of pages, end_data_segment is effectively rounded up to the next page boundary.</p>
</blockquote>
</li>
<li><p>program break可以设定的精确上限取决于</p>
<ul>
<li>进程中对数据段大小的资源限制<code>RLIMIT_DATA</code></li>
<li>内存映射</li>
<li>共享内存段</li>
<li>共享库的位置（因为堆向上增长就会遇到共享库的位置）</li>
</ul>
</li>
</ul>
<h3 id="page-cache和buffer-cache"><a href="#page-cache和buffer-cache" class="headerlink" title="page cache和buffer cache"></a>page cache和buffer cache</h3><ul>
<li><p>页缓存（page cache）针对以页为单位的所有操作，并考虑了特定体系结构上的页长度。内存映射技术、其他类型的文件访问也是基于内核中的这一技术实现的，所以页缓存实际上负责了块设备的大部分缓存工作</p>
</li>
<li><p>buffer cache</p>
<ul>
<li>a buffer is the in-memory representation of a single physical disk block. Buffers act as descriptors that map pages in memory to disk blocks;</li>
<li>the page cache（这个page cache应该是指buffer cache这种page cache）also reduces disk access during block I/O operations by both <strong>caching disk blocks</strong> and <strong>buffering block I/O operations</strong> until later</li>
<li>this caching is often referred to as the <strong>buffer cache</strong>, although as implemented it is not a separate cache but <strong>is part of the page cache</strong></li>
<li>In earlier kernels, there were two separate disk caches: the page cache and the buffer cache. <strong>The former cached pages; the latter cached buffers</strong>.The two caches were not unified: A disk block could exist in both caches simultaneously.</li>
<li>Today, we have one disk cache: the page cache. <strong>The kernel still needs to use buffers, however, to represent disk blocks in memory</strong>. Conveniently, <strong>the buffers describe the mapping of a block onto a page, which is in the page cache.</strong></li>
</ul>
</li>
</ul>
<h3 id="GCC内联汇编"><a href="#GCC内联汇编" class="headerlink" title="GCC内联汇编"></a>GCC内联汇编</h3><ul>
<li>以下来自<a href="http://csapp.cs.cmu.edu/3e/waside/waside-embedded-asm.pdf" target="_blank" rel="noopener">CSAPP Assembly Webaside</a></li>
<li>扩展形式的汇编的目的<ul>
<li>帮助编译器correctly set up the required source values, execute the assembly instructions, and make use of the computed results</li>
<li>important program values are not overwritten by the assembly code instructions</li>
</ul>
</li>
<li>形式：以<code>:</code>分割，依次为code-string、output-list(results generated by the assembly code)、input-list(results generated by the assembly code)、overwrite-list(registers that are overwritten by the assembly code)</li>
<li>code-string<ul>
<li>GCC3.1之前，在code-string中用<code>%0, %1, ..., %9</code>来引用output-list和input-list中的操作数（<code>%n</code>的<code>n</code>, based on the order of the operands in the two lists）</li>
<li>GCC3.1开始，可以使用<code>%[name]</code>来引用</li>
<li>寄存器名字用<code>%%reg_name</code>来引用</li>
<li>If multiple instructions are given, it is critical that <strong>return characters</strong> be inserted between them. 一种方法是（finish all but the final string with the sequence \n\t）</li>
</ul>
</li>
<li><p>output-string</p>
<ul>
<li>a comma-separated list</li>
<li><p>each list element containing three components in the form <code>[name] tag (expr)</code>(giving the name of the operand, the output constraint(specifies constraints on the use and location of the output operand), and the C expression indicating the destination for the instruction result)</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&quot;=r&quot; Update value stored in a register</span><br><span class="line">&quot;+r&quot; Read and update value stored in a register</span><br><span class="line">&quot;=m&quot; Update value stored in memory</span><br><span class="line">&quot;+m&quot; Read and update value stored in memory</span><br><span class="line">&quot;=rm&quot; Update value stored in a register or in memory</span><br><span class="line">&quot;+rm&quot; Read and update value stored in a register or in memory</span><br></pre></td></tr></table></figure>
</li>
<li><p>The expression expr can be any assignable value (known in C as an lvalue). The compiler will generate the necessary code sequence to perform the assignment</p>
</li>
</ul>
</li>
<li>input-string<ul>
<li>The input list entries have the same format as output-string</li>
<li>the tags are of the form tag “r”, “m”, or “rm”, indicating that the operand will be read from a register, memory, or either, respectively</li>
<li>Each input operand can be any C expression. The compiler will generate the necessary code to evaluate the expression</li>
</ul>
</li>
<li><p>overwrite-list</p>
<ul>
<li>Each input operand can be any C expression. The compiler will generate the necessary code to evaluate the expression</li>
</ul>
</li>
<li><p>we can simplify the code even more and make use of GCC’s ability to work with different data types. GCC uses the type information for an operand when determining which register to substitute for an operand name in the code string<br> 原先的版本，手动指定寄存器</p>
 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">tmult_ok2</span><span class="params">(<span class="keyword">long</span> x, <span class="keyword">long</span> y, <span class="keyword">long</span>* dest)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> result;</span><br><span class="line">    dest = x * y;</span><br><span class="line">    <span class="keyword">asm</span>(<span class="string">"setae %%bl # Set low-order byte\n\t"</span></span><br><span class="line">        <span class="string">"movzbl %%bl,%[val] # Zero extend to be result"</span></span><br><span class="line">        : [ val ] <span class="string">"=r"</span>(result) <span class="comment">/* Output */</span></span><br><span class="line">        :                      <span class="comment">/* No inputs */</span></span><br><span class="line">        : <span class="string">"%bl"</span>                <span class="comment">/* Overwrites */</span></span><br><span class="line">    );</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> 新版本，让GCC指定寄存器</p>
 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Uses extended asm to get reliable code */</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">tmult_ok3</span><span class="params">(<span class="keyword">long</span> x, <span class="keyword">long</span> y, <span class="keyword">long</span>* dest)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> bresult;</span><br><span class="line">    *dest = x * y;</span><br><span class="line">    <span class="keyword">asm</span>(<span class="string">"setae %[b] # Set result"</span></span><br><span class="line">        : [b] <span class="string">"=r"</span>(bresult) <span class="comment">/* Output */</span></span><br><span class="line">    );</span><br><span class="line">    <span class="keyword">return</span> (<span class="keyword">int</span>)bresult;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>例子</p>
 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">umult_ok</span><span class="params">(<span class="keyword">unsigned</span> <span class="keyword">long</span> x, <span class="keyword">unsigned</span> <span class="keyword">long</span> y, <span class="keyword">unsigned</span> <span class="keyword">long</span>* dest)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> bresult;</span><br><span class="line">    <span class="keyword">asm</span>(<span class="string">"movq %[x],%%rax # Get x\n\t"</span></span><br><span class="line">        <span class="string">"mulq %[y] # Unsigned long multiply by y\n\t"</span></span><br><span class="line">        <span class="string">"movq %%rax,%[p] # Store low-order 8 bytes at dest\n\t"</span></span><br><span class="line">        <span class="string">"setae %[b] # Set result"</span></span><br><span class="line">        : [p] <span class="string">"=m"</span>(*dest), [b] <span class="string">"=r"</span>(bresult) <span class="comment">/* Outputs */</span></span><br><span class="line">        : [x] <span class="string">"r"</span>(x), [y] <span class="string">"r"</span>(y)             <span class="comment">/* Inputs */</span></span><br><span class="line">        : <span class="string">"%rax"</span>, <span class="string">"%rdx"</span>                     <span class="comment">/* Overwrites */</span></span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (<span class="keyword">int</span>)bresult;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><blockquote>
<p>如果我们的汇编语句必须在我们放置它的地方执行，(即，必须不被作为一个优化而移出循环)，则将volatile放在asm之后。所以防止它被移动、删除和任何改变，我们如此声明<code>asm volatile(... : ... : ... : ...);</code> 当我们必须非常小心时，使用<code>__volatile__</code>。如果我们的汇编只是做一些计算而没有任何副作用，最好不要使用volatile关键字。忽略它将帮助GCC优化代码使其更优美。(Ref from<a href="https://www.jianshu.com/p/10e8a7b4f980" target="_blank" rel="noopener">译：GCC内联汇编入门</a>)</p>
</blockquote>
</li>
<li>受影响列表中的<code>memory</code>字样(<a href="https://gcc.gnu.org/onlinedocs/gcc/Extended-Asm.html" target="_blank" rel="noopener">Ref from</a>)<blockquote>
<ul>
<li>The “memory” clobber tells the compiler that the assembly code <strong>performs memory reads or writes to items other than those listed in the input and output operands (for example, accessing the memory pointed to by one of the input parameters)</strong>. </li>
<li><strong>To ensure memory contains correct values, GCC may need to flush specific register values to memory before executing the asm</strong>. </li>
<li>Further, the compiler does not assume that any values read from memory before an asm remain unchanged after that asm; it reloads them as needed.</li>
<li><strong>Using the “memory” clobber effectively forms a read/write memory barrier for the compiler.</strong></li>
<li>Note that this clobber does not prevent the processor from doing speculative reads past the asm statement. To prevent that, <strong>you need processor-specific fence instructions.</strong></li>
</ul>
</blockquote>
</li>
<li>受影响列表中的<code>cc</code>字样(<a href="https://gcc.gnu.org/onlinedocs/gcc/Extended-Asm.html" target="_blank" rel="noopener">Ref from</a>)<blockquote>
<ul>
<li>The “cc” clobber indicates that the assembler code modifies <strong>the flags register</strong> </li>
<li>On some machines, GCC represents the condition codes as a specific hardware register; “cc” serves to name this register. </li>
<li>On other machines, condition code handling is different, and specifying “cc” has no effect. But it is valid no matter what the target.</li>
</ul>
</blockquote>
</li>
</ul>
<h3 id="mutex"><a href="#mutex" class="headerlink" title="mutex"></a>mutex</h3><ul>
<li>文件锁（使用fcntl加锁、解锁一片文件区域）和信号量的锁定和解锁都需要syscall。mutex使用机器语言的原子操作（在内存中执行、对所有线程可见）来实现，只有发生锁争用时才需要syscall，所以mutex比前两者性能高</li>
<li>linux上的mutex使用futex（快速用户空间互斥量）实现，发生锁争用时调用futex syscall</li>
<li><strong>SUSv3规定，初始化一个已经初始化过的的互斥量将导致未定义行为</strong></li>
<li><strong>依照SUSv3的规定，对某一互斥量的副本（copy）执行各种操作将导致未定义的结果。此类操作只能施之于如下两类互斥量的“真身”</strong></li>
<li>静态分配的mutex可以使用<code>PTHREAD_MUTEX_INITIALIZER</code>初始化</li>
<li>在如下情况下，必须使用函数<code>pthread_mutex_init()</code>，而非静态初始化互斥量<ul>
<li>动态分配于堆中的互斥量</li>
<li>互斥量是在栈中分配的自动变量</li>
<li>初始化经由静态分配，且不使用默认属性的互斥量</li>
</ul>
</li>
<li>destroy mutex<ul>
<li>当不再需要经由自动或动态分配的互斥量时，应使用<code>pthread_mutex_destroy()</code>将其销毁</li>
<li>对于使用<code>PTHREAD_MUTEX_INITIALIZER</code>静态初始化的互斥量，无需调用<code>pthread_mutex_destroy()</code></li>
<li><strong>只有当互斥量处于未锁定状态，且后续也无任何线程企图锁定它时，将其销毁才是安全的</strong></li>
<li><strong>若互斥量驻留于动态分配的一片内存区域中，应在释放（free）此内存区域前将其销毁。对于自动分配的互斥量，也应在宿主函数返回前将其销毁</strong></li>
<li>经由<code>pthread_mutex_destroy()</code>销毁的互斥量，可调用<code>pthread_mutex_init()</code>对其重新初始化</li>
</ul>
</li>
<li>死锁解决方案<ul>
<li>定义互斥锁的层级关系，按照层级去获取锁</li>
<li>对于第一个锁使用<code>pthread_mutex_lock</code>，其他锁使用<code>try_lock</code>。如果有一个<code>try_lock</code>失败，则释放所有已获得的锁，一段时间后再试。这是通过解决“占有并等待”这个条件来解决问题的</li>
</ul>
</li>
</ul>
<h3 id="close-on-exec"><a href="#close-on-exec" class="headerlink" title="close-on-exec"></a>close-on-exec</h3><ul>
<li><blockquote>
<p>使用O_CLOEXEC标志(打开文件),可以免去程序执行fcntl()的F_GETFD和F_SETFD操作来设置close-on-exec标志的额外工作。在多线程程序中执行fcntl() 的F_GETFD和F_SETFD操作有可能导致竞争状态,而使用O_CLOEXEC标志则能够避免这一点。可能引发竞争的场景是:线程某甲打开一文件描述符,尝试为该描述符标记close-on-exec标志,于此同时,线程某乙执行fork()调用,然后调用exec()执行任意一个程序。(假设在某甲打开文件描述符和调用fcntl()设置close-on-exec标志之间,某乙成功地执行了fork()和exec()操作。)此类竞争可能会在无意间将打开的文件描述符泄露给不安全的程序</p>
</blockquote>
</li>
<li><blockquote>
<p>某些描述符可能是由库函数打开的。但库函数无法使主程序在执行exec()之前关闭相应的文件描述符。作为基本原则,库函数应总是为其打开的文件设置执行时关闭(close-on-exec)标志,稍后将介绍所使用的技术。如果exec()因某种原因而调用失败,可能还需要使描述符保持打开状态。如果这些描述符已然关闭,将它们重新打开并指向相同文件的难度很大,基本上不太可能</p>
</blockquote>
</li>
</ul>
<h3 id="sched-yield"><a href="#sched-yield" class="headerlink" title="sched_yield"></a><code>sched_yield</code></h3><blockquote>
<p>sched_yield()的操作是比较简单的。如果存在与调用进程的优先级相同的其他排队的可运行进程，那么调用进程会被放在队列的队尾，队列中队头的进程将会被调度使用CPU。如果在该优先级队列中不存在可运行的进程，那么sched_yield()不会做任何事情，调用进程会继续使用CPU。<strong>非实时进程使用sched_yield()的结果是未定义的</strong>。</p>
</blockquote>
<h3 id="mlock"><a href="#mlock" class="headerlink" title="mlock"></a><code>mlock</code></h3><ul>
<li><blockquote>
<p>Under  Linux,  mlock(),  mlock2(),  and munlock() automatically <strong>round addr down to the nearest page boundary</strong>.  However, the POSIX.1 specification of mlock() and munlock() allows an implementation to require that addr is page aligned, so portable applications should ensure this.(Ref from man page)</p>
</blockquote>
</li>
<li><p>可以避免被交换到swap分区，一般用于real-time进程。跟信息安全有关的进程也会这样做，避免内存page被交换到swap分区，从而hack可以从磁盘上读取这些信息，甚至是在进程结束后</p>
<blockquote>
<p>cryptographic security software often handles critical bytes like passwords or secret keys as data structures.  As a result of paging, these secrets could be transferred onto a persistent swap store medium, where they might be  accessible to the enemy  long <strong>after the security software has erased the secrets in RAM and terminated</strong>.</p>
</blockquote>
</li>
<li><blockquote>
<p>But be aware that the suspend mode on laptops and some desktop computers will save a copy of the system’s RAM to disk, regardless of memory locks.</p>
</blockquote>
</li>
</ul>
<h3 id="pthread"><a href="#pthread" class="headerlink" title="pthread"></a>pthread</h3><ul>
<li><p>joinable vs detached </p>
<ul>
<li>A thread may either be joinable or detached</li>
<li>If a thread is  joinable, then  another thread can call pthread_join(3) to wait for the thread to terminate and fetch its exit status</li>
<li><strong>Only when a  terminated  joinable thread  has  been joined are the last of its resources released back to the system</strong>(看起来就像进程的wait一样).</li>
<li><strong>When a detached thread terminates, its resources are automatically  released back to the system</strong>: it is not possible to join with the thread in order to obtain its exit status. <strong>Making  a  thread  detached is useful for some types of daemon threads whose exit status the application does not need to care about</strong>.</li>
<li><strong>By default, a new  thread  is created  in  a joinable state</strong>, unless attr was set to create the thread in a detached state (using pthread_attr_setdetachstate(3))</li>
<li><p>以下代码输出<code>Resource deadlock avoided</code></p>
 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> t = pthread_join(pthread_self(), <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span>(t!=<span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%s\n"</span>, strerror(t));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>以下代码不退出</p>
 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span>* <span class="title">func</span><span class="params">(<span class="keyword">void</span>* arg)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">pthread_t</span> tid;</span><br><span class="line">    <span class="keyword">int</span> t = pthread_create(&amp;tid, <span class="literal">NULL</span>, func, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span>(t!=<span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%s\n"</span>, strerror(t));</span><br><span class="line">    &#125;</span><br><span class="line">    pthread_exit(<span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>以下代码的问题是，主线程退出后，另一个线程对主线程栈上的内容进行操作，结果难以预料<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> *<span class="title">threadFunc</span><span class="params">(<span class="keyword">void</span> *arg)</span> </span>&#123;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">someStruct</span> *<span class="title">pbuf</span> = (<span class="title">struct</span> <span class="title">someStruct</span> *)<span class="title">arg</span>;</span></span><br><span class="line">  <span class="comment">/* Do some work with structure pointed to by 'pbuf' */</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span> </span>&#123;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">someStruct</span> <span class="title">buf</span>;</span></span><br><span class="line">  pthread_create(&amp;thr, <span class="literal">NULL</span>, threadFunc, (<span class="keyword">void</span> *)&amp;buf);</span><br><span class="line">  pthread_exit(<span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="条件变量"><a href="#条件变量" class="headerlink" title="条件变量"></a>条件变量</h3><ul>
<li>静态分配的条件变量可以使用<code>PTHREAD_COND_INITALIZER</code>来完成初始化</li>
</ul>
<h3 id="PIPE-and-FIFO"><a href="#PIPE-and-FIFO" class="headerlink" title="PIPE and FIFO"></a>PIPE and FIFO</h3><ul>
<li>可以确保写入不超过<code>PIPE_BUF</code>字节的操作是原子的。如果多个进程写入同一个管道,那么如果它们在一个时刻写入的数据量不超过PIPE_BUF字节,那么就可以确保写入的数据不会发生相互混合的情况</li>
<li>当写入管道的数据块的大小超过了PIPE_BUF字节,那么内核可能会将数据分割成几个较小的片段来传输,<strong>在读者从管道中消耗数据时再附加上后续的数据(write()调用会阻塞直到所有数据被写入到管道为止)。</strong></li>
<li>只有在数据被传输到管道的时候PIPE_BUF限制才会起作用<ul>
<li>当写入的数据达到<code>PIPE_BUF</code>字节时,write()会在必要的时候阻塞直到管道中的可用空间足以原子地完成操作</li>
<li>如果写入的数据大于<code>PIPE_BUF</code>字节,那么write()会尽可能地多传输数据以充满整个管道,然后阻塞直到一些读取进程从管道中移除了数据。如果此类阻塞的write()被一个信号处理器中断了,那么这个调用会被解除阻塞并返回成功传输到管道中的字节数,这个字节数会少于请求写入的字节数</li>
</ul>
</li>
<li>PIPE_BUF(Ref from <code>man 7 pipe</code>)<blockquote>
<ul>
<li>POSIX.1 says that write(2)s of less than PIPE_BUF bytes must be <strong>atomic: the output data is written to the pipe as a contiguous sequence</strong>.  </li>
<li>Writes  of more than PIPE_BUF bytes may be nonatomic: the kernel may interleave the data with data written by other processes.  </li>
<li>POSIX.1 requires PIPE_BUF to be at least 512 bytes.  (On Linux, PIPE_BUF is 4096 bytes.)  </li>
<li><p>The precise semantics depend on whether the file descriptor is  nonblocking  (O_NONBLOCK), whether there are multiple writers to the pipe, and on n, the number of bytes to be written:</p>
<ul>
<li><p>O_NONBLOCK disabled, n &lt;= PIPE_BUF<br>  <strong>All n bytes are written atomically</strong>; write(2) may block if there is not room for n bytes to be written immediately</p>
</li>
<li><p>O_NONBLOCK enabled, n &lt;= PIPE_BUF<br>  If  there is room to write n bytes to the pipe, then write(2) <strong>succeeds immediately, writing all n bytes</strong>; <strong>otherwise write(2) fails, with errno set to EAGAIN.</strong></p>
</li>
<li><p>O_NONBLOCK disabled, n &gt; PIPE_BUF<br>  The write is nonatomic: the data given to write(2) may be interleaved with write(2)s by other process; <strong>the write(2) blocks until n bytes have been written</strong>.</p>
</li>
<li><p>O_NONBLOCK enabled, n &gt; PIPE_BUF</p>
<pre><code>**If the pipe is full**, then write(2) fails, with errno set to EAGAIN.  **Otherwise, from 1 to n bytes may be written** (i.e., a &quot;partial write&quot; may occur; the caller should check the return value from write(2) to see how many bytes were actually written), and these  bytes  may  be  interleaved with writes by other processes.
</code></pre></li>
</ul>
</li>
</ul>
</blockquote>
</li>
</ul>
<h3 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h3><h4 id="调优方法"><a href="#调优方法" class="headerlink" title="调优方法"></a>调优方法</h4><ul>
<li>ext2有<blockquote>
<p>快速符号链接，如果链接目标的路径足够短，则将其存储在inode自身中（不是存储在数据区中）<br> 所以可以减小文件名长度来加速</p>
</blockquote>
</li>
</ul>
<h3 id="用户凭证"><a href="#用户凭证" class="headerlink" title="用户凭证"></a>用户凭证</h3><h4 id="passwd-5"><a href="#passwd-5" class="headerlink" title="passwd(5)"></a><code>passwd(5)</code></h4><ul>
<li>The encrypted password field may be blank, in which case no password is required to authenticate as the specified login name. However, <strong>some applications which read the /etc/passwd file may decide not to permit any access at all if the password field is blank</strong>.(我去掉<code>x</code>后，ubuntu图形界面可以登录，无需密码，zsh的sudo不行，输了原来的密码也不行) </li>
<li>If the password field is a lower-case “x”, then the encrypted password is actually stored in the shadow(5) file instead; there must be a corresponding line in the /etc/shadow file, or else the user account is invalid. </li>
<li>If the password field is any other string, then it will be treated as an encrypted password, as specified by crypt(3).</li>
</ul>
<h3 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h3><h4 id="open"><a href="#open" class="headerlink" title="open"></a><code>open</code></h4><ul>
<li>如果在<code>open()</code>调用中指定<code>O_CREAT</code>标志，那么还需要提供mode参数，否则，会将新文件的权限设置为栈中的某个随机值。</li>
<li></li>
</ul>
<h3 id="同一个bin，第一次启动慢的原因"><a href="#同一个bin，第一次启动慢的原因" class="headerlink" title="同一个bin，第一次启动慢的原因"></a>同一个bin，第一次启动慢的原因</h3><ul>
<li>需要加载共享库</li>
</ul>
<h3 id="Linux-dev"><a href="#Linux-dev" class="headerlink" title="Linux dev"></a>Linux dev</h3><ul>
<li>NPTL dev: Ulrich Drepper和Ingo Molnar</li>
</ul>
<h3 id="MISC-1"><a href="#MISC-1" class="headerlink" title="MISC"></a>MISC</h3><ul>
<li>需要对目录有<code>x</code>权限才能cd进目录</li>
</ul>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Linux/" rel="tag"># Linux</a>
          
            <a href="/tags/CFS/" rel="tag"># CFS</a>
          
            <a href="/tags/epoll/" rel="tag"># epoll</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/05/01/My-CSAPP-Note/" rel="next" title="My CSAPP Note">
                <i class="fa fa-chevron-left"></i> My CSAPP Note
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/07/10/java-concurrency-note-2/" rel="prev" title="My Java Concurrent Note(2)">
                My Java Concurrent Note(2) <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
    </div>

  



        </div>
        
          
  

  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">H-ZeX</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">39</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">19</span>
                    <span class="site-state-item-name">categories</span>
                  
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">69</span>
                    <span class="site-state-item-name">tags</span>
                  
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/H-ZeX" title="GitHub &rarr; https://github.com/H-ZeX" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:hzx20112012@gmail.com" title="E-Mail &rarr; mailto:hzx20112012@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Linux调度"><span class="nav-text">Linux调度</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#CFS"><span class="nav-text">CFS</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Real-time-scheduling"><span class="nav-text">Real-time scheduling</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Multiprocessor-scheduling"><span class="nav-text">Multiprocessor scheduling</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Adjusting-priority"><span class="nav-text">Adjusting priority</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#misc"><span class="nav-text">misc</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#进程状态"><span class="nav-text">进程状态</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#僵尸进程、孤儿进程"><span class="nav-text">僵尸进程、孤儿进程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#进程内存布局"><span class="nav-text">进程内存布局</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MISC"><span class="nav-text">MISC</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SO-REUSEPORT"><span class="nav-text">SO_REUSEPORT</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PTHREAD-STACK-MIN"><span class="nav-text">PTHREAD_STACK_MIN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#IO"><span class="nav-text">IO</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#网络编程"><span class="nav-text">网络编程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#epoll"><span class="nav-text">epoll</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#惊群"><span class="nav-text">惊群</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#命令"><span class="nav-text">命令</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#top"><span class="nav-text">top</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#free"><span class="nav-text">free</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#vmstat"><span class="nav-text">vmstat</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HugePage"><span class="nav-text">HugePage</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#malloc"><span class="nav-text">malloc</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#page-cache和buffer-cache"><span class="nav-text">page cache和buffer cache</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GCC内联汇编"><span class="nav-text">GCC内联汇编</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mutex"><span class="nav-text">mutex</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#close-on-exec"><span class="nav-text">close-on-exec</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sched-yield"><span class="nav-text">sched_yield</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mlock"><span class="nav-text">mlock</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#pthread"><span class="nav-text">pthread</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#条件变量"><span class="nav-text">条件变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PIPE-and-FIFO"><span class="nav-text">PIPE and FIFO</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#文件系统"><span class="nav-text">文件系统</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#调优方法"><span class="nav-text">调优方法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#用户凭证"><span class="nav-text">用户凭证</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#passwd-5"><span class="nav-text">passwd(5)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#文件操作"><span class="nav-text">文件操作</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#open"><span class="nav-text">open</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#同一个bin，第一次启动慢的原因"><span class="nav-text">同一个bin，第一次启动慢的原因</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Linux-dev"><span class="nav-text">Linux dev</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MISC-1"><span class="nav-text">MISC</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">H-ZeX</span>

  

  
</div>


  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.7.1</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.0.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=7.0.0"></script>

  <script src="/js/src/motion.js?v=7.0.0"></script>



  
  


  <script src="/js/src/affix.js?v=7.0.0"></script>

  <script src="/js/src/schemes/pisces.js?v=7.0.0"></script>



  
  <script src="/js/src/scrollspy.js?v=7.0.0"></script>
<script src="/js/src/post-details.js?v=7.0.0"></script>



  


  <script src="/js/src/bootstrap.js?v=7.0.0"></script>



  
  

<script src="//cdn1.lncld.net/static/js/3.11.1/av-min.js"></script>



<script src="//unpkg.com/valine/dist/Valine.min.js"></script>

<script>
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: true,
    appId: '2zewWM7OPwRwvylk6pRcPGm7-gzGzoHsz',
    appKey: 'qPGJQQgN9YMXkOQLEC97Ufhf',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false
  });
</script>




  


  





  

  

  

  

  
  

  
  

  


  

  

  

  

  

  

  

  
  

  
  

  


</body>
</html>
